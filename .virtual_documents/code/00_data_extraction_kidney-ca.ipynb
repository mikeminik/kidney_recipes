import numpy as np
import pandas as pd
import requests
import time
import os
from bs4 import BeautifulSoup






def extract_visible_urls(source):
    # create a list of individual recipe URLs from "visible" HTML
    recipe_urls = []
    for item in source:
        if item.find('a') != None:
            link = item.find('a').attrs['href']
            recipe_urls.append(link)
    return recipe_urls


def get_file_name(url):
    # create a "file name" that is created from the URL that is primarily used to identify the ingredients
    file_name = url.split('recipes/')[1].strip('/')
    return file_name


def extract_recipe_info(url, omit_tags = []):
    # given a recipe page's url, extract key recipe info
    # includes option to check visible tags to make sure non-desirable recipes are omitted (such as high protein)
    
    time.sleep(3)
    print(f"Getting information from: {url}")
    # extracts ingredients from a specific recipes
    
    ingredients_text = []
    tags = []
    
    # make request and soup
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'}
    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        print(f"{url} request status: {res.status_code}")
    soup = BeautifulSoup(res.content)
    
    # get the tags
    if soup.find('span', {'class': 'cat-links'}):
        for a in soup.find_all('span', {'class': 'cat-links'})[0].find_all('a'):
            tags.append(a.text)

    # if tags are not ideal, skip the rest
    if not any(string in tags for string in omit_tags):
        # get the serving size
        if (soup.find('div', {'class': lambda name : 'diet-analysis' in name if name else False}).find('p', string = lambda t : 'servings' in t.lower() if t else False)):
            serving_size = soup.find('div', {'class': lambda name : 'diet-analysis' in name if name else False}). \
            find('p', string = lambda t : 'servings' in t.lower() if t else False).text
        else:
            serving_size = None


        # Ingredients: focus in on the element that contains ingredients using 'li' first
        ingredients_div = soup.find_all('div', {'class': lambda x: 'ingredients' in x if x else False})
        ingredient_items = [ result.find_all('li') for result in ingredients_div]

        # Ingredients: if first pass above yields no results, try for 'p' elements instead
        if len(ingredient_items[0]) == 0:
            ingredient_items = [ result.find_all('p') for result in ingredients_div]

        [ingredients_text.append(l.text) for l in ingredient_items[0]]
        
        
        nutrition_data = [item.text.split(':') for item in soup.find_all('ul', {'class':'list-group'})[0].find_all('li')]
        calories = None
        totfat = None
        protein = None
        sodium = None
        potassium = None
        phosphorus = None
        
        for i in nutrition_data:
            if i[0].lower().strip() == 'calories':
                calories = i[1]
            elif i[0].lower().strip() == 'total fat':
                totfat = i[1]
            elif i[0].lower().strip() == 'protein':
                protein = i[1]
            elif i[0].lower().strip() == 'sodium':
                sodium = i[1]
            elif i[0].lower().strip() == 'potassium':
                potassium = i[1]
            elif i[0].lower().strip() == 'phosphorus':
                phosphorus = i[1]
        
        nutrition = {'calories': calories,
                     'saturated fat': totfat,
                     'protein': protein,
                     'sodium': sodium,
                     'potassium': potassium,
                     'phosphorus': phosphorus
                    }
        
        return serving_size, ingredients_text, nutrition
    print(f"Alert: Skipped recipe at url: {url} due to non-ideal nutrient tags")
    return None, None, None




def scrape_page(url, omit_tags):
    # primary function, intended to be used once per result page
    page_recipes = []
    
    # make the primary request and create soup
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'}
    res = requests.get(url, headers=headers)
    print(f"Primary call status: {res.status_code}")
    primary_soup = BeautifulSoup(res.content)
    
    
    # get h2s (the clickable recipe blocks)
    h2s = primary_soup.find_all('h2', {'class' : 'entry-title card-title'})
    
    # pass h2s to secondary url extraction func and get list of recipe urls for that page
    visible_urls = extract_visible_urls(h2s)
    
    # run the ingredient extractor secondary func
    for u in visible_urls:
        # file_name = get_file_name(u)
        serving, ingredients, nutrition = extract_recipe_info(u, omit_tags)
        if not any(value == None for value in [serving, ingredients,nutrition]):
            page_recipes.append({'url': u,
                                'serving_size': serving,
                                'ingredients_raw': ingredients,
                                'calories': nutrition['calories'],
                                'saturated fat': nutrition['saturated fat'],
                                'protein': nutrition['protein'],
                                'sodium': nutrition['sodium'],
                                'potassium': nutrition['potassium'],
                                'phosphorus': nutrition['phosphorus'] 
                               })
    return page_recipes
        








all_recipes = []





bad_tags = ['High Protein', 'High Sodium', 'High Potassium']
initial_url = 'https://www.kidneycommunitykitchen.ca/kkcookbook/recipes/'
page_results = scrape_page(initial_url, bad_tags)
for result in page_results:
    all_recipes.append(result)






for i in range(2, 15):
    print(f"Page: {i}")
    page_results = scrape_page(initial_url+'?_paged='+str(i), bad_tags)
    for result in page_results:
        all_recipes.append(result)


all_recipes_df = pd.DataFrame(all_recipes)


all_recipes_df.to_csv('kidney-ca-recipes-with-ingredients-and-nutrition.csv')




